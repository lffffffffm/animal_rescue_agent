from loguru import logger
from typing import List, Union
import torch
from langchain_core.embeddings import Embeddings

from app.config import settings

_default_embedding_manager = None


class EmbeddingManager:
    """
    åµŒå…¥æ¨¡å‹ç®¡ç†ç±»
    ç”¨äºåˆå§‹åŒ–å’Œç®¡ç†æœ¬åœ°åµŒå…¥æ¨¡å‹ï¼ˆç¦»çº¿ä¼˜å…ˆï¼‰
    """

    def __init__(self, model_name: str):
        """
        åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ç®¡ç†å™¨

        Args:
            model_name: åµŒå…¥æ¨¡å‹åç§° (å¯ä»¥æ˜¯ HF repo_id æˆ–æœ¬åœ°è·¯å¾„)
        """
        self.model_name = model_name
        self._embeddings = None
        self._initialize_embeddings()

    def _initialize_embeddings(self):
        """
        åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆç¦»çº¿ä¼˜å…ˆï¼‰ã€‚
        - ä¼˜å…ˆä½¿ç”¨ settings.EMBEDDING_MODEL_PATH
        - settings.EMBEDDING_OFFLINE=true æ—¶ï¼Œå¼ºåˆ¶åªç”¨æœ¬åœ°æ–‡ä»¶ï¼Œç¦æ­¢è”ç½‘
        """
        try:
            from langchain_huggingface import HuggingFaceEmbeddings
            from sentence_transformers import SentenceTransformer

            offline = str(settings.EMBEDDING_OFFLINE).lower() == 'true'
            local_path = settings.EMBEDDING_MODEL_PATH

            # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„é…ç½®ï¼Œå¦åˆ™ä½¿ç”¨ä¼ å…¥çš„ model_name
            model_to_load = local_path if local_path else self.model_name

            if not model_to_load:
                raise ValueError("æœªæŒ‡å®šåµŒå…¥æ¨¡å‹ã€‚è¯·è®¾ç½® EMBEDDING_MODEL_PATH æˆ– EMBEDDING_MODELã€‚")

            # éªŒè¯æ¨¡å‹èƒ½å¦åŠ è½½
            try:
                # å…³é”®ï¼šlocal_files_only=offline å†³å®šæ˜¯å¦è”ç½‘
                SentenceTransformer(model_to_load, local_files_only=offline)
            except Exception as e:
                logger.error(f"æ— æ³•åŠ è½½åµŒå…¥æ¨¡å‹ '{model_to_load}' (offline={offline})ã€‚é”™è¯¯: {e}")
                if offline:
                    raise RuntimeError(
                        f"ç¦»çº¿æ¨¡å¼ä¸‹åŠ è½½æ¨¡å‹å¤±è´¥ã€‚è¯·æ£€æŸ¥ EMBEDDING_MODEL_PATH ('{local_path}') æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è®¾ç½® EMBEDDING_OFFLINE=false ä»¥å…è®¸ä¸‹è½½ã€‚"
                    )
                # å¦‚æœå…è®¸è”ç½‘ä½†å¤±è´¥ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸å†å›é€€
                raise e

            # åˆå§‹åŒ– LangChain Embeddings
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self._embeddings = HuggingFaceEmbeddings(
                model_name=model_to_load,
                model_kwargs={"device": device,"trust_remote_code": True},
                encode_kwargs={"normalize_embeddings": True},
            )

            logger.info(f"å·²åŠ è½½ Embedding æ¨¡å‹: {model_to_load} (offline={offline})")

        except ImportError as e:
            logger.error(f"ç¼ºå°‘å¿…è¦çš„ä¾èµ–: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–åµŒå…¥æ¨¡å‹å¤±è´¥: {str(e)}")
            raise

    @property
    def embeddings(self) -> Embeddings:
        """
        è·å–åµŒå…¥æ¨¡å‹å®ä¾‹
        """
        if self._embeddings is None:
            self._initialize_embeddings()
        return self._embeddings

    @property
    def dimension(self) -> int:
        """è·å–å½“å‰æ¨¡å‹çš„å‘é‡ç»´åº¦ï¼Œç”¨äº Qdrant åˆå§‹åŒ–"""
        # é¢„è¿è¡Œä¸€æ¬¡ï¼Œè·å–ç»´åº¦
        test_vec = self.embed_query("ç»´åº¦æ¢æµ‹")
        return len(test_vec)

    def embed_texts(self, texts: Union[str, List[str]], batch_size: int = 32) -> List[List[float]]:
        """
        å¯¹æ–‡æœ¬è¿›è¡ŒåµŒå…¥ç¼–ç 
        """
        if isinstance(texts, str):
            texts = [texts]
        try:
            results = []
            for i in range(0, len(texts), batch_size):
                batch = texts[i: i + batch_size]
                results.extend(self._embeddings.embed_documents(batch))
            return results
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ–‡æœ¬åµŒå…¥å¤±è´¥: {str(e)}")
            raise

    def embed_query(self, query: str) -> List[float]:
        """
        å¯¹æŸ¥è¯¢æ–‡æœ¬è¿›è¡ŒåµŒå…¥ç¼–ç 
        """
        try:
            embedding_result = self._embeddings.embed_query(query)
            logger.debug(f"æˆåŠŸç”ŸæˆæŸ¥è¯¢ '{query[:50]}...' çš„åµŒå…¥å‘é‡")
            return embedding_result
        except Exception as e:
            logger.error(f"ç”ŸæˆæŸ¥è¯¢åµŒå…¥å¤±è´¥: {str(e)}")
            raise


def get_embedding() -> Embeddings:
    """
    è·å–å…¨å±€å”¯ä¸€çš„ Embeddings å®ä¾‹ï¼ˆå•ä¾‹ï¼‰
    ä» settings ä¸­è¯»å–æ¨¡å‹åç§°ã€‚
    """
    global _default_embedding_manager

    if _default_embedding_manager is None:
        logger.info("ğŸ”§ åˆå§‹åŒ–å…¨å±€ EmbeddingManager ...")
        # ä» settings è¯»å–æ¨¡å‹åï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 
        model_name_from_settings = settings.EMBEDDING_MODEL
        _default_embedding_manager = EmbeddingManager(model_name=model_name_from_settings)

    return _default_embedding_manager.embeddings


def initialize_embedding_model() -> EmbeddingManager:
    """
    åˆå§‹åŒ–åµŒå…¥æ¨¡å‹çš„ä¾¿æ·å‡½æ•°
    """
    # ä» settings è¯»å–æ¨¡å‹å
    model_name_from_settings = settings.EMBEDDING_MODEL
    return EmbeddingManager(model_name=model_name_from_settings)


if __name__ == "__main__":
    pass